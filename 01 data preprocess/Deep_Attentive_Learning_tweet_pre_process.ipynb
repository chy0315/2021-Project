{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw7PdUcdG4wX"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icAgmR8HG6PW",
        "outputId": "47ed7090-d74b-4b6e-8303-90aa46e8b168"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        " \n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_list = drive.ListFile({'q': \"'1DIF8C7O9SUS3puW3NHXymKa2Nz3GG8L7' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "    if file1['title'] == 'raw_tweet.zip':\n",
        "        preprocessorFile = drive.CreateFile({'id': file1['id']})\n",
        "        preprocessorFile.GetContentFile('raw_tweet.zip')\n",
        "        print('title: %s, id: %s is downloaded' % (file1['title'], file1['id']))\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljDuY3h1Icto",
        "outputId": "989fba8a-59e7-4294-b55e-66b77bfe92e8"
      },
      "outputs": [],
      "source": [
        "!unzip raw_tweet.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qcxfQdzMs3Z"
      },
      "outputs": [],
      "source": [
        "!rm raw_tweet.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbvUoMffF9-S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep5oPZp4pn4u"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('preprocessed/GMRE'):\n",
        "    os.mkdir('preprocessed/GMRE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGyckKZbF_yw"
      },
      "outputs": [],
      "source": [
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP4YtxkTReqo"
      },
      "outputs": [],
      "source": [
        "empty_embedding = embed(['']).numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-vcexJVBnTq",
        "outputId": "4fedaf03-8286-46c2-c36b-d403e6e8477c"
      },
      "outputs": [],
      "source": [
        "for fname in ['train_timestamp.csv', 'test_timestamp.csv', 'valid_timestamp.csv']:\n",
        "    timestamps_df = pd.read_csv(fname)\n",
        "    tweets_text = []\n",
        "    print(f'{fname} stage 1 in process', flush=True)\n",
        "    stage_max_tweet = 0\n",
        "    limit_max_tweet = 10\n",
        "    for i, allow_date in enumerate(tqdm(timestamps_df['Date'].values)):\n",
        "        tweets_text.append([])\n",
        "        for j, stock_name in enumerate(sorted(os.listdir('preprocessed'))):\n",
        "            if allow_date in sorted(os.listdir(f'preprocessed/{stock_name}')):\n",
        "                with open(f'preprocessed/{stock_name}/{allow_date}') as f:\n",
        "                    lines = f.readlines()\n",
        "                    if len(lines) > limit_max_tweet:\n",
        "                        lines = random.sample(lines,limit_max_tweet)\n",
        "                    tweets = [' '.join(json.loads(tweet).get('text')) for tweet in lines]\n",
        "                embeddings = embed(tweets)\n",
        "                tweets_text[-1].append(embeddings.numpy())\n",
        "                if len(lines) < limit_max_tweet:\n",
        "                    need = limit_max_tweet - len(lines)\n",
        "                    tweets_text[i][j] = np.vstack([tweets_text[i][j],np.array([empty_embedding]*need)])\n",
        "            else:\n",
        "                tweets_text[-1].append(np.array([empty_embedding]*limit_max_tweet))\n",
        "    tweets_text = np.array([np.array(i) for i in tweets_text])\n",
        "    print(tweets_text.shape)\n",
        "\n",
        "    root = 'tweet_output'\n",
        "    if not os.path.exists(root):\n",
        "        os.mkdir(root)\n",
        "    filename = os.path.join(root, fname.split('_')[0] + '_tweet.npy')\n",
        "    with open(filename, 'wb') as fn:\n",
        "        np.save(fn, tweets_text)\n",
        "        print('File saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLJBPROeramo",
        "outputId": "15358c50-5bbe-48c0-fb43-4ca3c24d5a89"
      },
      "outputs": [],
      "source": [
        "!ls -l tweet_output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qly3pTzkeSUa",
        "outputId": "d5c6bc75-fde6-450f-dad1-2ef6e642e109"
      },
      "outputs": [],
      "source": [
        "stock_key_seq = np.array(sorted(os.listdir('preprocessed')))\n",
        "with open('tweet_output/stock_key_seq.npy', 'wb') as fn:\n",
        "    np.save(fn, stock_key_seq)\n",
        "    print('File saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_iO6gSxI_FI",
        "outputId": "3c32dd69-fd30-4f05-ea95-805f0fd7751a"
      },
      "outputs": [],
      "source": [
        "!zip -r tweet_output.zip tweet_output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Deep Attentive Learning tweet pre-process",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}